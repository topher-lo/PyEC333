{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tough-matter",
   "metadata": {},
   "source": [
    "# Introduction to MLE (and MAP)\n",
    "---\n",
    "## Overview\n",
    "We will be looking at parameter estimation in this notebook. In particular, we will be:\n",
    "- Defining distributions\n",
    "- Plotting likelihood functions\n",
    "- Estimating parameters\n",
    "- Comparing numerical methods (that estimate parameters even in the absence of a closed-form solution)\n",
    "\n",
    "I thought this would be a good opportunity to introduce maximum a posteriori (MAP), which is a Bayesian method for parameter estimation. MAP incorporates a prior distribution over the possible values of the parameter to be estimated.\n",
    "\n",
    "**CAUTION:** this is NOT an introduction to Bayesian inference. My intention is to provide examples where **prior information** *might* help with parameter estimation. Note:\n",
    "- MAP is not representative of Bayesian inference. A MAP estimate is a point estimate equal to the mode of the posterior distribution. In general, Bayesians consider parameters and hypotheses as random variables. As random variables, you can (in most cases) meaningfully report statistics of the posterior distribution other than the mode (e.g. mean, standard deviation).\n",
    "- There are unsolved problems with regards to the intepretation of prior probabilities. These problems are anathema to frequentists and divide (philosophically inclined) Bayesians (see https://plato.stanford.edu/entries/epistemology-bayesian/#PotPro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "killing-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(12,9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-mortality",
   "metadata": {},
   "source": [
    "# 1. Distributions and likelihood functions\n",
    "\n",
    "## MLE:\n",
    "- We will be using `scipy`: a Python library for scientific computing. \n",
    "- `scipy` was introduced in the previous notebook on limited binary outcomes. `scipy` was used to implement Tobit from scratch.\n",
    "- Do not worry if you had difficulty understanding the Tobit implementation! \n",
    "- The examples in this notebook are a lot more straightforward than the Tobit example, which required us to specify a piece-wise likelihood function. We will revisit the Tobit implementation at the end of this notebook.\n",
    "\n",
    "## MAP:\n",
    "- We will be using `pymc3`: a high-level Python library for Bayesian inference via probabalistic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-gothic",
   "metadata": {},
   "source": [
    "## 1.1 Normal distribution\n",
    "- Recall that the general form of the Gaussian probability distribution function (PDF) is given by:\n",
    "\n",
    "$$ {\\displaystyle f(x)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {x-\\mu }{\\sigma }}\\right)^{2}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's define the pdf of the Normal distribution from scratch\n",
    "\n",
    "def gaussian_pdf(mu: float,\n",
    "                 sigma: float,\n",
    "                 x: float) -> float:\n",
    "    \"\"\"Given mu, sigma, and a single observation x, \n",
    "    return the value of the Gaussian pdf.\n",
    "    \"\"\"\n",
    "    sigma_2 = sigma**2\n",
    "    pi = scipy.pi\n",
    "    a1 = (sigma_2*2*pi)**-(1/2)\n",
    "    a2 = -1/(2*sigma_2)*(x-mu)**2\n",
    "    y = a1*np.exp(a2)\n",
    "    return y\n",
    "\n",
    "\n",
    "# 2. Let's define the likelihood and log-likelihood\n",
    "\n",
    "def gaussian_likelihood(pdf, params, X, ll=False):\n",
    "    \"\"\"Given a Gaussian pdf, params (mu, sigma), and a \n",
    "    vector X of observations, return the value of the Gaussian \n",
    "    likelihood function.\n",
    "    \n",
    "    Note: if ll=True, returns the log-likelihood value.\n",
    "    \"\"\"\n",
    "    def _pdf(mu, sigma, ll):\n",
    "        \"\"\"Converts the pdf function into a sequence of\n",
    "        functions, where the inner-most function takes a \n",
    "        single argument x.\n",
    "\n",
    "        This design pattern is called \"currying\".\n",
    "        \"\"\"\n",
    "        def _pdf_x(x):\n",
    "            if not(ll):\n",
    "                func = pdf(mu, sigma, x)\n",
    "            else:\n",
    "                func = np.log(pdf(mu, sigma, x))\n",
    "            return func\n",
    "        return _pdf_x\n",
    "    \n",
    "    mu, sigma = params\n",
    "    \n",
    "    # Map X to the pdf / log-pdf function\n",
    "    val_seq = np.array(list(map(_pdf(mu, sigma, ll), X)))   \n",
    "    \n",
    "    # If likelihood\n",
    "    if not(ll):\n",
    "        # Apply the PRODUCT operator\n",
    "        value = np.prod(val_seq)\n",
    "    # If log-likelihood\n",
    "    else:\n",
    "        # Apply SUMMATION\n",
    "        value = sum(val_seq)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-seller",
   "metadata": {},
   "source": [
    "## 1.2 Bernoulli distribution\n",
    "- Recall that the general form of the Bernoulli probability mass function (PMF) is given by:\n",
    "\n",
    "$$ {\\displaystyle f(x;p)= p^{x}(1-p)^{1-x}} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's define the Bernoulli distribution\n",
    "\n",
    "def bernoulli_pmf(p: float, x: int) -> float:\n",
    "    \"\"\"Given probability of success p and a single observation x, \n",
    "    return the value of the Bernoulli pmf.\n",
    "    \"\"\"\n",
    "    y = p**x*(1-p)**(1-x)\n",
    "    return y\n",
    "    \n",
    "\n",
    "# 2. Let's define the likelihood and log-likelihood\n",
    "\n",
    "def bernoulli_likelihood(pmf, p, X, ll):\n",
    "    \"\"\"Given a Bernoulli pmf, params (mu, sigma), and a \n",
    "    vector X of observations, return the value of the Gaussian \n",
    "    likelihood function.\n",
    "    \n",
    "    Note: if ll=True, returns the log-likelihood value.\n",
    "    \"\"\"\n",
    "    def _pmf(p, ll):\n",
    "        \"\"\"Converts the pmf function into a sequence of\n",
    "        functions, where the inner-most function takes a \n",
    "        single argument x.\n",
    "\n",
    "        This design pattern is called \"currying\".\n",
    "        \"\"\"\n",
    "        def _pmf_x(x):\n",
    "            if not(ll):\n",
    "                func = pmf(p, x)\n",
    "            else:\n",
    "                func = np.log(pmf(p, x))\n",
    "            return func\n",
    "        return _pmf_x\n",
    "\n",
    "    # Map X to the pdf / log-pdf function\n",
    "    val_seq = np.array(list(map(_pmf(p, ll), X)))   \n",
    "    \n",
    "    # If likelihood\n",
    "    if not(ll):\n",
    "        # Apply the PRODUCT operator\n",
    "        value = np.prod(val_seq)\n",
    "    # If log-likelihood\n",
    "    else:\n",
    "        # Apply SUMMATION\n",
    "        value = sum(val_seq)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-premiere",
   "metadata": {},
   "source": [
    "# 2. Plotting likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-berkeley",
   "metadata": {},
   "source": [
    "## 2.1 Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let create a sample of size N=50 that is drawn from a normal distribution \n",
    "# with mean = 0 and sigma = 1\n",
    "\n",
    "mu, sigma, N = 0, 1, 50\n",
    "X_normal = np.random.normal(mu, sigma, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the gaussian likelihood on a 3D plane (likelihood value, mu, sigma)\n",
    "# by defining a range of possible mu and sigma values.\n",
    "# Use numpy's linspace function to create an array of decimal step values\n",
    "\n",
    "mu_range = np.linspace(-1, 1, num=100)\n",
    "sigma_range = np.linspace(0.05, 4.5, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate likelihood values\n",
    "\n",
    "# 1. Compute the Cartesian product of mu_range and sigma_range\n",
    "mu_sigma_seq = itertools.product(mu_range, sigma_range)\n",
    "\n",
    "# 2. Apply gaussian_likelihood in a list comprehension over sequence from 1.\n",
    "# 2.1 Likelihood\n",
    "likelihood_val_seq = [gaussian_likelihood(gaussian_pdf,\n",
    "                                          (mu, sigma),\n",
    "                                          X_normal,\n",
    "                                          ll=False)\n",
    "                      for mu, sigma in mu_sigma_seq]\n",
    "\n",
    "# 2.2. Log-likliehood\n",
    "log_likelihood_val_seq = [gaussian_likelihood(gaussian_pdf,\n",
    "                                              (mu, sigma),\n",
    "                                              X_normal,\n",
    "                                              ll=True)\n",
    "                          for mu, sigma in mu_sigma_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Gaussian likelihood function in 3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Gaussian log-likelihood function in 3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-dairy",
   "metadata": {},
   "source": [
    "## 2.2. Bernoulli distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-television",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-worth",
   "metadata": {},
   "source": [
    "# 3. Numerical optimisation in Python\n",
    "- `scipy` only has a minimiser.\n",
    "- Therefore, we need to use negative likelihoods / negative log-likelihoods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ec333] *",
   "language": "python",
   "name": "conda-env-ec333-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
